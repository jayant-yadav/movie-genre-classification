{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGTJm-VTever"
      },
      "outputs": [],
      "source": [
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzHA5u9nevew"
      },
      "outputs": [],
      "source": [
        "!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkNRwGgzfI1M",
        "outputId": "a7ffa333-8c6e-4fc2-f98c-a0f4d76077ad"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZBDlBdchaxf"
      },
      "outputs": [],
      "source": [
        "!unzip gdrive/My\\ Drive/movies/metadata.zip\n",
        "!unzip gdrive/My\\ Drive/movies/dataset.zip \n",
        "!unzip gdrive/My\\ Drive/movies/croppedonce.zip \n",
        "!unzip gdrive/My\\ Drive/movies/cropped.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHzAcngKZNSJ"
      },
      "outputs": [],
      "source": [
        "#!unzip gdrive/My\\ Drive/movieset/trainingsmall.zip \n",
        "#!unzip gdrive/My\\ Drive/movieset/testingsmall.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V0MlomrGAhhg",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Natural Computation Methods for ML\\Project\\NCML_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import shutil\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data_utils\n",
        "from torch.nn.modules import MSELoss, L1Loss\n",
        "\n",
        "import sklearn.preprocessing\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import glob\n",
        "import csv\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wo0qf35reve0"
      },
      "outputs": [],
      "source": [
        "# path1 = \"./Movie_Poster_Metadata/groundtruth\"\n",
        "# temp_path = \"./Movie_Poster_Metadata/temp_groundtruth\"\n",
        "# path2 = \"./Movie_Poster_Metadata/updated_groundtruth\"\n",
        "# cropped_dataset = \"./Dataset_Cropped\"\n",
        "# Jay's gdrive paths:\n",
        "path1 = \"./Movie_Poster_Metadata/groundtruth\"\n",
        "temp_path = \"./Movie_Poster_Metadata/temp_groundtruth\"\n",
        "path2 = \"./Movie_Poster_Metadata/updated_groundtruth\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snqkcEj7eve1"
      },
      "source": [
        "### Reading the input file and creating a clean one\n",
        "Note: only run once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Z_gG-mC7eve3",
        "outputId": "a309dd0a-4609-40b1-98e7-6309bd72e0b5"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "dir_list = os.listdir(path1)\n",
        " \n",
        "if not os.path.exists(temp_path):\n",
        "  os.makedirs(temp_path)    \n",
        "\n",
        "if not os.path.exists(path2):\n",
        "  os.makedirs(path2)\n",
        "\n",
        "\n",
        "\n",
        "for file_name in dir_list:\n",
        "    \n",
        "    with open(path1+'/'+file_name,'r',encoding='utf-16-le') as file1:\n",
        "\n",
        "        temp_file = open(temp_path+'/'+file_name,'w',encoding='utf-8')\n",
        "\n",
        "        for line in file1.readlines():\n",
        "\n",
        "            line = line.replace(\"}\\n\",\"},\\n\")\n",
        "            \n",
        "            # reading all lines that begin with \"  \"_id\"\"\n",
        "            y = re.findall(\"^  \\\"_id\\\"\", line)\n",
        "            if not y:\n",
        "                temp_file.write(line)\n",
        "\n",
        "    file1.close()\n",
        "    temp_file.close()\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "OxohJlpieve6",
        "outputId": "9d069ecc-7444-47a1-f8bc-8590fea62bb3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "dir_list = os.listdir(temp_path)\n",
        " \n",
        "for file_name in dir_list:\n",
        "    \n",
        "    with open(temp_path+'/'+file_name,'r',encoding='utf-8') as temp_file:\n",
        "    \n",
        "        file2 = open(path2+'/'+file_name,'w',encoding='utf-8')\n",
        "\n",
        "        lines = temp_file.readlines()\n",
        "        lines = lines[1:-1]\n",
        "\n",
        "        file2.write(\"[{\")\n",
        "        file2.writelines(lines)\n",
        "        file2.write(\"}]\")\n",
        "        \n",
        "    temp_file.close()\n",
        "    file2.close()\n",
        "\n",
        "shutil.rmtree(temp_path)  \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q8-JNQ4eve7"
      },
      "source": [
        "### Augmenting the data set\n",
        "Note: only run once\n",
        "\n",
        "To-Do: Balance data according to occurence of genres. Summarize genres with little data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "SBlOuf5aeve9",
        "outputId": "24810e28-88ad-40c1-b699-54a1db29e38e"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "path3 = \"./Movie_Poster_Dataset\"\n",
        "\n",
        "# Going through all jpg-files, they are chopped up into 100x100 chunks and saved into a new folder\n",
        "for dirname in os.listdir(path3):\n",
        "    for filename in os.listdir(path3 + \"/\" + dirname):\n",
        "        name, ext = os.path.splitext(filename)\n",
        "        if(ext == '.jpg'):\n",
        "            image = Image.open(os.path.join(path3 + \"/\" + dirname, filename))\n",
        "            width, height = image.size\n",
        "            chopsize = 100\n",
        "            for x0 in range(0, width, chopsize):\n",
        "                for y0 in range(0, height, chopsize):\n",
        "                    if(y0+chopsize <= height and x0+chopsize <= width):\n",
        "                        box = (x0, y0, x0+chopsize, y0+chopsize)\n",
        "                        image.crop(box).save('gdrive/MyDrive/movies/Movie_Poster_Dataset_Cropped/%s.x%03d.y%03d.jpg' % (filename.replace('.jpg',''), x0, y0))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "9YKiuwACeve_",
        "outputId": "7f928851-570b-418c-808e-bc6c569bdd06"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "path3 = \"'gdrive/MyDrive/movies/Movie_Poster_Dataset\"\n",
        "\n",
        "# Going through all jpg-files, they are chopped up into 100x100 chunks and saved into a new folder\n",
        "for dirname in os.listdir(path3):\n",
        "    for filename in os.listdir(path3 + \"/\" + dirname):\n",
        "        name, ext = os.path.splitext(filename)\n",
        "        if(ext == '.jpg'):\n",
        "            image = Image.open(os.path.join(path3 + \"/\" + dirname, filename))\n",
        "            box = (0, 0, 100, 100)\n",
        "            image.crop(box).save('./Movie_Poster_Dataset_Cropped_Once/%s.jpg' % (filename))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "mRwNR4vzevfA",
        "outputId": "b8f55a71-92fd-471a-811f-23e4eea7bfe3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "#to be used later to augment data of underrepresented genres (balance data)\n",
        "\n",
        "print('Nr of movies in json: '+str(len(dicts)))\n",
        "missing = []\n",
        "for obj in dicts:\n",
        "    genrelist = obj.get('Genre').split(',')\n",
        "    fname = obj.get('imdbID') + '.jpg'\n",
        "    if(path.exists(fname)):\n",
        "        for genre in genrelist:\n",
        "            #copy the file with name obj.key(\"imdbID\") to each genre folder\n",
        "            if(genre == 'N/A'):\n",
        "                shutil.copy2(os.path.join('.', fname), './NotApplicable')\n",
        "            elif(genre == 'Adult' || genre == 'Game-Show' || genre == 'News' || genre == 'Reality-TV' || genre == 'Talk-Show' || genre == 'Western'):\n",
        "                shutil.copy2(os.path.join('.', fname), './Other')\n",
        "            else:\n",
        "                shutil.copy2(os.path.join('.', fname), './'+genre.lstrip())\n",
        "    else:\n",
        "        missing.append(fname)\n",
        "\n",
        "\n",
        "print('Nr of missing IDs: '+str(len(missing)))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOd-ltaPevfB"
      },
      "source": [
        "### Function to append all the json objects into dataframe "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "pUpfYvtWevfB",
        "outputId": "b46cb49f-258c-4218-d436-84ff5ac5813a",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "dir_list = os.listdir(path2)\n",
        "\n",
        "movies_df = pd.DataFrame()\n",
        "\n",
        "for file_name in dir_list:    \n",
        "\n",
        "#     try:\n",
        "    df = pd.read_json(path2+'/'+file_name,encoding='utf-8',orient='records')\n",
        "    df = df[['imdbID','Director','Genre','imdbRating']]\n",
        "    movies_df = pd.concat([movies_df,df], ignore_index=True)\n",
        "\n",
        "#     except:\n",
        "#         print(file_name)\n",
        "        \n",
        "# print(movies_df.dtypes)\n",
        "# print(movies_df.head(20))\n",
        "# print(movies_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkmXxvUBevfC"
      },
      "source": [
        "### Creating multi-hot encoded genre vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DXEDdPjaevfC"
      },
      "outputs": [],
      "source": [
        "#remove duplicates and set imdbID as index\n",
        "movies_df = movies_df.drop_duplicates(subset=[\"imdbID\"], keep=\"last\")\n",
        "movies_df.set_index(\"imdbID\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_gx5brSevfD",
        "outputId": "3f07b798-b96d-4915-a7e6-19611704ec52"
      },
      "outputs": [],
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "multihot = mlb.fit_transform(movies_df[\"Genre\"].dropna().str.split(\", \"))\n",
        "genres_df = pd.DataFrame({\"multihot\":[multihot.astype(int)]}, index = movies_df.index)\n",
        "movies_df = pd.concat([movies_df, genres_df], axis=1 )\n",
        "# print(mlb.classes_)\n",
        "# print(movies_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wJd1F0g-evfD"
      },
      "outputs": [],
      "source": [
        "#create a dictionary with multi-hot encoded vectors; index = imdbID\n",
        "multihot_dict = {movies_df.index.tolist()[i] : multihot[i] for i in range(0, len(multihot))}\n",
        "#print(multihot_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsZB9cOIevfE"
      },
      "source": [
        "### Adding the images to the dataframe\n",
        "Note: not used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOW3UMBxevfE",
        "outputId": "a54e4d62-bc2d-41e3-a34e-2dd077d3fde9"
      },
      "outputs": [],
      "source": [
        "flist=glob.glob('./Movie_Poster_Dataset/*/*.jpg')\n",
        "\n",
        "imdb_id_arr = [\"0\" for a in range(len(flist))]\n",
        "image_arr = [\"0\" for a in range(len(flist))]\n",
        "index = 0\n",
        "\n",
        "for filename in flist:\n",
        "        \n",
        "    imdb_id = filename[filename.index(\"tt\"):filename.index(\".jpg\")]\n",
        "        \n",
        "    imdb_id_arr[index] = imdb_id\n",
        "                \n",
        "    img = np.array(cv2.imread(filename))\n",
        "    img = np.swapaxes(img, 2,0)\n",
        "    img = np.swapaxes(img, 2,1)\n",
        "    \n",
        "    image_arr[index] = img\n",
        "    \n",
        "    index +=1 \n",
        "        \n",
        "image_dict = {\n",
        "    \"imdbID\": imdb_id_arr,\n",
        "    \"Poster\": image_arr\n",
        "}\n",
        "\n",
        "images_df = pd.DataFrame.from_dict(image_dict)\n",
        "images_df = images_df.drop_duplicates(subset=[\"imdbID\"], keep=\"last\")\n",
        "images_df.set_index(\"imdbID\", inplace=True)\n",
        "movies_df = pd.concat([movies_df, images_df], axis=1)\n",
        "print(movies_df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6syvhuE-yj2m"
      },
      "source": [
        "## Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FANO93KTyif-"
      },
      "outputs": [],
      "source": [
        "#training controls\n",
        "batch_size = 10\n",
        "number_of_labels = 28\n",
        "epochs = 5\n",
        "training_size = 0.7\n",
        "learning_rate = 0.001\n",
        "dropout = [0.3, 0.3, 0.3, 0.3, 0.2, 0.2, 0.2, 0.2, 0.15]\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 100, 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXI9-JvvevfF"
      },
      "source": [
        "### Passing the images through a convolutional network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b0axZikbevfF"
      },
      "outputs": [],
      "source": [
        "# the data holders\n",
        "x_test = []\n",
        "x_train = []\n",
        "y_test = []\n",
        "y_train = []\n",
        "\n",
        "#images need to have the same size!!\n",
        "flist=glob.glob('./Movie_Poster_Dataset_Cropped_Once/*.jpg')\n",
        "\n",
        "length=int(len(flist)*training_size)\n",
        "i = 0\n",
        "\n",
        "#create lists with input data (images) and output data (multi-hot encoded genre vectors)\n",
        "for filename in flist:\n",
        "        \n",
        "    imdb_id = filename[filename.index(\"tt\"):filename.index(\".jpg\")]\n",
        "      \n",
        "    if imdb_id in multihot_dict:\n",
        "        img = np.array(cv2.imread(filename))\n",
        "        img = np.swapaxes(img, 2,0)\n",
        "        img = np.swapaxes(img, 2,1)\n",
        "        \n",
        "        genre_arr = np.empty([28])\n",
        "        \n",
        "        for j in range(len(multihot_dict[imdb_id])):\n",
        "            genre_arr[j] = multihot_dict[imdb_id][j]\n",
        "    \n",
        "        if(i<length):  \n",
        "            x_train.append(img)\n",
        "            y_train.append(genre_arr)\n",
        "        else:\n",
        "            x_test.append(img)\n",
        "            y_test.append(genre_arr)\n",
        "        \n",
        "        i +=1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waUcfZkSevfG",
        "outputId": "99a5acbb-a719-48f7-9214-4300059ea6ca"
      },
      "outputs": [],
      "source": [
        "# print(len(x_train))\n",
        "# print(len(y_train))\n",
        "\n",
        "# print(len(x_train[0]))\n",
        "# print(len(y_train[0]))\n",
        "\n",
        "# print(len(x_test[0]))\n",
        "# print(len(y_test[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "770N0xHeevfH",
        "outputId": "de125dfb-4f01-4c95-c264-cb991c2d0b04",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (5636, 3, 100, 100)\n",
            "5636 train samples\n",
            "2416 test samples\n"
          ]
        }
      ],
      "source": [
        "#converting the data from lists to numpy arrays\n",
        "x_train=np.asarray(x_train,dtype=float)\n",
        "x_test=np.asarray(x_test,dtype=float)\n",
        "y_train=np.asarray(y_train,dtype=float)\n",
        "y_test=np.asarray(y_test,dtype=float)\n",
        "\n",
        "#scaling down the RGB data\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "#printing stats about the features\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "train_length = x_train.shape[0]\n",
        "\n",
        "x_train=torch.from_numpy(x_train)\n",
        "x_test=torch.from_numpy(x_test)\n",
        "y_train=torch.from_numpy(y_train)\n",
        "y_test=torch.from_numpy(y_test)\n",
        "\n",
        "train = data_utils.TensorDataset(x_train, y_train)\n",
        "train_loader = data_utils.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test = data_utils.TensorDataset(x_test, y_test)\n",
        "test_loader = data_utils.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdbLrLz4p0K8"
      },
      "source": [
        "### DenseNet-121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TyK6balPp9LZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\Dell/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DenseNet(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (denseblock1): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition1): _Transition(\n",
            "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock2): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition2): _Transition(\n",
            "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock3): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition3): _Transition(\n",
            "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock4): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=28, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True) # TODO: Modify the fully connected layer of denseNet\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False \n",
        "    # Replace the last fully-connected layer\n",
        "    # Parameters of newly constructed modules have requires_grad=True by default\n",
        "# num_ftrs = model.fc.in_features # num_ftrs = 1024\n",
        "# model.classifier = nn.Linear(num_ftrs, 28)\n",
        "# model.fc = nn.Linear(num_ftrs, 28) \n",
        "# sigmoid = nn.Sigmoid(model.fc)\n",
        "# sigmoid(model.fc)\n",
        "#TODO: make a sigmoid activation func, decision threshold of 0.3\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(1024, 28),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "\n",
        "model.double() \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"model loaded on {device}\")\n",
        "model.to(device) #hopefully runs model on cuda core.\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5iWf_9WpfaP"
      },
      "source": [
        "## Custom CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJvV2PKLevfI",
        "outputId": "f4a2e994-2348-4881-9206-c8484994e7c2"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, input_shape=(3, img_rows, img_cols)):\n",
        "        super(Network, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 128, kernel_size=2)\n",
        "        self.conv1_drop = nn.Dropout2d(p=dropout[0])\n",
        "        self.conv2 = nn.Conv2d(128, 64, kernel_size=2)\n",
        "        self.conv2_drop = nn.Dropout2d(p=dropout[1])\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=2)\n",
        "        self.conv3_drop = nn.Dropout2d(p=dropout[2])\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=2)\n",
        "        self.conv4_drop = nn.Dropout2d(p=dropout[3])\n",
        "        self.conv5 = nn.Conv2d(64, 32, kernel_size=2)\n",
        "        self.conv5_drop = nn.Dropout2d(p=dropout[4])\n",
        "        self.conv6 = nn.Conv2d(32, 16, kernel_size=2)\n",
        "        self.conv6_drop = nn.Dropout2d(p=dropout[5])\n",
        "        \n",
        "        n_size = self._get_conv_output(input_shape)\n",
        "        \"\"\"\n",
        "        self.fc1 = nn.Linear(n_size, 16)\n",
        "        self.fc1_drop = nn.Dropout(p=dropout[6])\n",
        "        self.fc2 = nn.Linear(16, 16)\n",
        "        self.fc2_drop = nn.Dropout(p=dropout[7])\n",
        "        self.fc3 = nn.Linear(16, 8)\n",
        "        self.fc3_drop = nn.Dropout(p=dropout[8])\n",
        "        self.fc4 = nn.Linear(8, 28)\n",
        "        \"\"\"\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.fc1 = nn.Linear(n_size, 28)\n",
        "\n",
        "        \n",
        "    def _get_conv_output(self, shape):\n",
        "        bs = 1\n",
        "        input = Variable(torch.rand(bs, *shape))\n",
        "        output_feat = self._forward_features(input)\n",
        "        n_size = output_feat.data.view(bs, -1).size(1)\n",
        "        return n_size\n",
        "        \n",
        "    def _forward_features(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1_drop(self.conv1(x)), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(x)), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv4_drop(self.conv4(x)), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv5_drop(self.conv5(x)), 2))\n",
        "        #x = F.relu(F.max_pool2d(self.conv6_drop(self.conv6(x)), 2))\n",
        "        return x\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1_drop(self.conv1(x)), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(x)), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv4_drop(self.conv4(x)), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv5_drop(self.conv5(x)), 2))\n",
        "        #x = F.relu(F.max_pool2d(self.conv6_drop(self.conv6(x)), 2))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.sigmoid(x)\n",
        "        # x = torch.sigmoid(self.fc1(x))\n",
        "\n",
        "        #x = F.relu(self.fc1_drop(self.fc1(x)))\n",
        "        #x = F.relu(self.fc2_drop(self.fc2(x)))\n",
        "        #x = F.relu(self.fc3_drop(self.fc3(x)))\n",
        "        #x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# model = Network()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4jb48Z8rtgX"
      },
      "source": [
        "## Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0) #TODO: check best params here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ0kg2ICmmdq"
      },
      "source": [
        "## Train and Test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZQIvRfhTevfI"
      },
      "outputs": [],
      "source": [
        "# Function to save the model\n",
        "def saveModel():\n",
        "    path = \"./myFirstModel.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "# Function to test the model with the test dataset and print the accuracy for the test images\n",
        "def testAccuracy():\n",
        "    \n",
        "    model.eval() #TODO: check model.train() which is used along model.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"model testing on {device}\")\n",
        "        some_accuracy_measure = 0\n",
        "        final_accuracy = 0\n",
        "        for i, (images, labels) in enumerate(test_loader,0):\n",
        "            sum = 0\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "            outputs = model(images) \n",
        "            print(outputs)\n",
        "            for j, label in enumerate(labels):\n",
        "              n = sum + label.sum().item()\n",
        "              # get the top n values of outputs\n",
        "              _, predicted = torch.topk(outputs[j], int(n)) #TODO: change logic to Matthews correlation coeffcients\n",
        "              correct_predictions = 0\n",
        "              for _, k in enumerate(predicted):\n",
        "                if(label[k.item()].item() == 1):\n",
        "                  correct_predictions += 1\n",
        "                some_accuracy_measure = correct_predictions/n\n",
        "            final_accuracy += some_accuracy_measure  \n",
        "            # the label with the highest energy will be our prediction\n",
        "            #_, predicted = torch.max(outputs.data, 1)\n",
        "            #print(\"Predicted: \", predicted)\n",
        "            total += labels.size(0)\n",
        "            \n",
        "            #accuracy += (predicted == labels).sum().item()\n",
        "    print(\"Total: \", total)\n",
        "    # compute the accuracy over all test images\n",
        "    #accuracy = (100 * accuracy / total)\n",
        "    accuracy = final_accuracy * 100 /total\n",
        "    print(\"Accuracy;: \", accuracy)\n",
        "    return(accuracy)\n",
        "\n",
        "\n",
        "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
        "def train(num_epochs):\n",
        "    \n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Define your execution device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"The model will be running on\", device, \"device\")\n",
        "    # Convert model parameters and buffers to CPU or Cuda\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader, 0):\n",
        "            \n",
        "            # get the inputs\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "            #labels = labels.unsqueeze_(0)\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # predict classes using images from the training set\n",
        "            outputs = model(images)\n",
        "            # compute the loss based on model output and real labels\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            # adjust parameters based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Let's print statistics for every 1,000 images\n",
        "            running_loss += loss.item()     # extract the loss value\n",
        "            if i % 1000 == 999:    \n",
        "                # print every 1000 (twice per epoch) \n",
        "                #print('[%d, %5d] loss: %.3f' %\n",
        "                #      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                # zero the loss\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
        "        accuracy = testAccuracy() #BUG: why is this in for loop? \n",
        "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
        "        \n",
        "        # we want to save the model if the accuracy is the best\n",
        "        if accuracy > best_accuracy:\n",
        "            saveModel()\n",
        "            best_accuracy = accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8V_GcgfnZLf"
      },
      "source": [
        "## Functions to display sample output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRs5CZQvevfK"
      },
      "outputs": [],
      "source": [
        "# Function to show the images\n",
        "def imageshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Function to test the model with a batch of images and show the labels predictions\n",
        "def testBatch():\n",
        "    # get batch of images from the test DataLoader  \n",
        "    images, labels = next(iter(test_loader))\n",
        "\n",
        "    # show all images as one image grid\n",
        "    imageshow(torchvision.utils.make_grid(images))\n",
        "   \n",
        "    # Show the real labels on the screen \n",
        "    print('Real labels: ', ' '.join('%5s' % classes[labels[j]] \n",
        "                               for j in range(batch_size)))\n",
        "  \n",
        "    # Let's see what if the model identifiers the  labels of those example\n",
        "    outputs = model(images)\n",
        "    \n",
        "    # We got the probability for every 10 labels. The highest (max) probability should be correct label\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    \n",
        "    # Let's show the predicted labels on the screen to compare with the real ones\n",
        "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] \n",
        "                              for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUJJvd51rPzK"
      },
      "source": [
        "## Run Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmm4YxLMevfL",
        "outputId": "b98246b5-ccce-4d20-d087-450ddcce777c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model will be running on cpu device\n"
          ]
        }
      ],
      "source": [
        "# for epoch in range(0, epochs):\n",
        "\n",
        "train(epochs)\n",
        "    #test()\n",
        "\n",
        "accuracy = testAccuracy()\n",
        "print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
        "\n",
        "best_accuracy = 0\n",
        "# we want to save the model if the accuracy is the best\n",
        "if accuracy > best_accuracy:\n",
        "    saveModel()\n",
        "    best_accuracy = accuracy\n",
        "\n",
        "#TODO: plot learning curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWazb0fHevfL"
      },
      "source": [
        "### Passing the images through object detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3jEunoNevfL"
      },
      "outputs": [],
      "source": [
        "batch_size = 20\n",
        "epochs = 2\n",
        "training_size = 0.7\n",
        "learning_rate = 0.001\n",
        "img_rows, img_cols = 100, 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657,
          "referenced_widgets": [
            "d9833ad6c061421fa1dcf49b5f00e5b8",
            "5a5ea84b8e83467eb5d961c364d83825",
            "a047c55ff7d34d09bc2edad3bc0a8f74",
            "12cd445dee6141bab273f863bc056b97",
            "8f13d96fa74946feaf554203bf85be78",
            "c8aea7f8a7f74b66901fa40cab85f54d",
            "93428984473b4a58af76c084af385928",
            "505c084379f843f394176405667555e7",
            "917679b09108478caa052a430a0d0644",
            "926a503b1e7d49818bb08634bef0e35c",
            "71f54cda456b4e6e8d2c3e54a6fe2336"
          ]
        },
        "id": "5I8RKlyEevfM",
        "outputId": "ed9b6aed-ee17-49fc-babd-5e92965f0583"
      },
      "outputs": [],
      "source": [
        "# the data holders\n",
        "x_test_yolo = []\n",
        "x_train_yolo = []\n",
        "y_test_yolo = []\n",
        "y_train_yolo = []\n",
        "\n",
        "#images need to have the same size!!\n",
        "flist=glob.glob('./Movie_Poster_Dataset_Cropped_Once/*.jpg')\n",
        "\n",
        "#pretrained YOLOv5 model\n",
        "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "length=int(len(flist)*training_size)\n",
        "i = 0\n",
        "\n",
        "#create lists with input data (object confidence vector) and output data (multi-hot encoded genre vectors)\n",
        "for filename in flist:\n",
        "        \n",
        "    imdb_id = filename[filename.index(\"tt\"):filename.index(\".jpg\")]\n",
        "      \n",
        "    if imdb_id in multihot_dict:\n",
        "        img = np.array(cv2.imread(filename))\n",
        "        img = np.swapaxes(img, 2,0)\n",
        "        img = np.swapaxes(img, 2,1)\n",
        "        \n",
        "        results = yolo_model(img, size = 100)\n",
        "            \n",
        "        #create an array for the 91 object categories and set initial confidence to 0\n",
        "        obj_arr = np.empty([91])\n",
        "        for x in range(91):\n",
        "            obj_arr[x] = 0.0\n",
        "\n",
        "        #update the confidence values according to the object detection results\n",
        "        for obj in results.pandas().xyxy[0]:\n",
        "            index =  results.pandas().xyxy[0]['class']\n",
        "            obj_arr[index] = obj_arr[index] + results.pandas().xyxy[0].confidence\n",
        "        \n",
        "        #create multi-hot encoded genre vector\n",
        "        genre_arr = np.empty([28])\n",
        "\n",
        "        for j in range(len(multihot_dict[imdb_id])):\n",
        "            genre_arr[j] = multihot_dict[imdb_id][j]\n",
        "        \n",
        "        if(i<length):                   \n",
        "            x_train_yolo.append(obj_arr)\n",
        "            y_train_yolo.append(genre_arr)\n",
        "        else:\n",
        "            x_test_yolo.append(obj_arr)\n",
        "            y_test_yolo.append(genre_arr)\n",
        "        \n",
        "        i +=1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ23NN21evfN"
      },
      "outputs": [],
      "source": [
        "#converting the data from lists to numpy arrays\n",
        "x_train_yolo=np.asarray(x_train_yolo,dtype=float)\n",
        "x_test_yolo=np.asarray(x_test_yolo,dtype=float)\n",
        "y_train_yolo=np.asarray(y_train_yolo,dtype=float)\n",
        "y_test_yolo=np.asarray(y_test_yolo,dtype=float)\n",
        "\n",
        "#printing stats about the features\n",
        "print('x_train shape:', x_train_yolo.shape)\n",
        "print(x_train_yolo.shape[0], 'train samples')\n",
        "print(x_test_yolo.shape[0], 'test samples')\n",
        "\n",
        "train_length = x_train_yolo.shape[0]\n",
        "\n",
        "x_train_yolo=torch.from_numpy(x_train_yolo)\n",
        "x_test_yolo=torch.from_numpy(x_test_yolo)\n",
        "y_train_yolo=torch.from_numpy(y_train_yolo)\n",
        "y_test_yolo=torch.from_numpy(y_test_yolo)\n",
        "\n",
        "train = data_utils.TensorDataset(x_train_yolo, y_train_yolo)\n",
        "train_loader = data_utils.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test = data_utils.TensorDataset(x_test_yolo, y_test_yolo)\n",
        "test_loader = data_utils.DataLoader(test, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnrUeKK2evfN"
      },
      "outputs": [],
      "source": [
        "#fully connected layer after object detection\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        #fully connected layer\n",
        "        self.fc1 = nn.Linear(91, 28)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "model = Net()\n",
        "\n",
        "result = model.train()\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate,\n",
        "            alpha=0.9, eps=1e-08, weight_decay=0.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPVp7s4bevfO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "snqkcEj7eve1",
        "0Q8-JNQ4eve7",
        "VOd-ltaPevfB",
        "AkmXxvUBevfC",
        "OsZB9cOIevfE",
        "TXI9-JvvevfF",
        "L5iWf_9WpfaP",
        "tJ0kg2ICmmdq",
        "t8V_GcgfnZLf",
        "zWazb0fHevfL"
      ],
      "name": "genre_classification.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "95e1d69f56d8e2a587436622babdf358ae56e3753491c465a4bfef20ca6b03f3"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 ('NCML_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12cd445dee6141bab273f863bc056b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_926a503b1e7d49818bb08634bef0e35c",
            "placeholder": "​",
            "style": "IPY_MODEL_71f54cda456b4e6e8d2c3e54a6fe2336",
            "value": " 14.1M/14.1M [00:00&lt;00:00, 84.7MB/s]"
          }
        },
        "505c084379f843f394176405667555e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a5ea84b8e83467eb5d961c364d83825": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8aea7f8a7f74b66901fa40cab85f54d",
            "placeholder": "​",
            "style": "IPY_MODEL_93428984473b4a58af76c084af385928",
            "value": "100%"
          }
        },
        "71f54cda456b4e6e8d2c3e54a6fe2336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f13d96fa74946feaf554203bf85be78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "917679b09108478caa052a430a0d0644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "926a503b1e7d49818bb08634bef0e35c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93428984473b4a58af76c084af385928": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a047c55ff7d34d09bc2edad3bc0a8f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_505c084379f843f394176405667555e7",
            "max": 14808437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_917679b09108478caa052a430a0d0644",
            "value": 14808437
          }
        },
        "c8aea7f8a7f74b66901fa40cab85f54d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9833ad6c061421fa1dcf49b5f00e5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a5ea84b8e83467eb5d961c364d83825",
              "IPY_MODEL_a047c55ff7d34d09bc2edad3bc0a8f74",
              "IPY_MODEL_12cd445dee6141bab273f863bc056b97"
            ],
            "layout": "IPY_MODEL_8f13d96fa74946feaf554203bf85be78"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
